{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0334c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = \"Resampling_Data\"\n",
    "OUTPUT_PATH = \"Padding_Data\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, \"val\"), exist_ok=True)\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7964e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import json\n",
    "\n",
    "def pad_to_multiple(array, multiple=32, mode='constant', value=0):\n",
    "    \"\"\"\n",
    "    Pad array so that each spatial dimension is a multiple of `multiple`.\n",
    "    Returns padded array and padding info: [(pad_before, pad_after), ...]\n",
    "    \"\"\"\n",
    "    shape = array.shape\n",
    "    pad_width = []\n",
    "    \n",
    "    for dim in shape:\n",
    "        total_pad = (multiple - dim % multiple) % multiple\n",
    "        pad_before = total_pad // 2\n",
    "        pad_after = total_pad - pad_before\n",
    "        pad_width.append((pad_before, pad_after))\n",
    "\n",
    "    padded = np.pad(array, pad_width, mode=mode, constant_values=value)\n",
    "    return padded, pad_width\n",
    "\n",
    "def update_metadata_with_padding(metadata, pad_width):\n",
    "    metadata['padding'] = pad_width\n",
    "    return metadata\n",
    "\n",
    "def process_and_pad(dir_name, image_path, mask_path, metadata_path, out_path, padding_multiple=32):\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    # Load data\n",
    "    image = np.load(image_path)\n",
    "    mask = np.load(mask_path)\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Padding\n",
    "    padded_image, pad_width_img = pad_to_multiple(image, multiple=padding_multiple, mode='constant', value=0)\n",
    "    padded_mask, pad_width_mask = pad_to_multiple(mask, multiple=padding_multiple, mode='constant', value=0)\n",
    "\n",
    "    assert pad_width_img == pad_width_mask, \"Image and mask padding must match\"\n",
    "\n",
    "    # Update metadata\n",
    "    updated_metadata = update_metadata_with_padding(metadata, pad_width_img)\n",
    "\n",
    "    # Save\n",
    "    # print(padded_image.shape)\n",
    "    # print(padded_image.shape)\n",
    "    # print(padded_image.nbytes / 1024**3, \"GB\")  # 打印大小（单位：GB）\n",
    "    # basename = os.path.splitext(os.path.basename(image_path))[0].replace(\"_resampled\", \"\")\n",
    "    # test_array = np.zeros((100, 100, 100), dtype=np.float32)\n",
    "    # np.save(os.path.join(out_path, \"test.npy\"), test_array)\n",
    "\n",
    "    np.save(os.path.join(out_path, \"GED4.npy\"), padded_image)\n",
    "    np.save(os.path.join(out_path, \"mask_GED4.npy\"), padded_mask)\n",
    "\n",
    "    with open(os.path.join(out_path, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(updated_metadata, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Padded data saved to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f371c8b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resampling_Data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dir_list = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_DATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, dir_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dir_list):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(TRAIN_DATA_PATH, dir_name)):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Resampling_Data/train'"
     ]
    }
   ],
   "source": [
    "dir_list = os.listdir(TRAIN_DATA_PATH)\n",
    "for idx, dir_name in enumerate(dir_list):\n",
    "    if not os.path.isdir(os.path.join(TRAIN_DATA_PATH, dir_name)):\n",
    "        continue\n",
    "    tmp_GED4 = os.path.join(TRAIN_DATA_PATH, dir_name, \"GED4.npy\")\n",
    "    tmp_mask = os.path.join(TRAIN_DATA_PATH, dir_name, \"mask_GED4.npy\")\n",
    "    tmp_metadata = os.path.join(TRAIN_DATA_PATH, dir_name, \"metadata.json\")\n",
    "    \n",
    "    output_dir = os.path.join(OUTPUT_PATH, \"train\", dir_name)\n",
    "    padded_GED4 = process_and_pad(dir_name, tmp_GED4, tmp_mask, tmp_metadata, output_dir, padding_multiple=32)\n",
    "\n",
    "dir_list = os.listdir(VAL_DATA_PATH)\n",
    "for idx, dir_name in enumerate(dir_list):\n",
    "    if not os.path.isdir(os.path.join(VAL_DATA_PATH, dir_name)):\n",
    "        continue\n",
    "    tmp_GED4 = os.path.join(VAL_DATA_PATH, dir_name, \"GED4.npy\")\n",
    "    tmp_mask = os.path.join(VAL_DATA_PATH, dir_name, \"mask_GED4.npy\")\n",
    "    tmp_metadata = os.path.join(VAL_DATA_PATH, dir_name, \"metadata.json\")\n",
    "    \n",
    "    output_dir = os.path.join(OUTPUT_PATH, \"val\", dir_name)\n",
    "    padded_GED4 = process_and_pad(dir_name, tmp_GED4, tmp_mask, tmp_metadata, output_dir, padding_multiple=32)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a3595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original shape is (180, 240, 380), (64, 520, 640)\n",
      "The original spacing is [[0.5938000082969666, 0.5938000082969666, 3.5]]\n",
      "[[[4, 4], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([172, 238, 380])\n",
      "The resampled shape is torch.Size([2, 172, 238, 380])\n",
      "The original shape is (180, 240, 380), (72, 260, 320)\n",
      "The original spacing is [[1.1875, 1.1875, 3.0]]\n",
      "[[[7, 7], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([166, 238, 380])\n",
      "The resampled shape is torch.Size([2, 166, 238, 380])\n",
      "The original shape is (160, 240, 380), (64, 260, 320)\n",
      "The original spacing is [[1.1875, 1.1875, 3.0]]\n",
      "[[[6, 6], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([148, 238, 380])\n",
      "The resampled shape is torch.Size([2, 148, 238, 380])\n",
      "The original shape is (200, 240, 380), (80, 260, 320)\n",
      "The original spacing is [[1.1875, 1.1875, 3.0]]\n",
      "[[[7, 8], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([185, 238, 380])\n",
      "The resampled shape is torch.Size([2, 185, 238, 380])\n",
      "The original shape is (180, 240, 380), (72, 260, 320)\n",
      "The original spacing is [[1.1875, 1.1875, 3.0]]\n",
      "[[[7, 7], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([166, 238, 380])\n",
      "The resampled shape is torch.Size([2, 166, 238, 380])\n",
      "The original shape is (140, 160, 300), (59, 169, 250)\n",
      "The original spacing is [[1.1875, 1.1875, 3.0]]\n",
      "[[[2, 2], [3, 3], [1, 2]]]\n",
      "Output shape after removing padding: torch.Size([136, 154, 297])\n",
      "The resampled shape is torch.Size([2, 136, 154, 297])\n",
      "The original shape is (180, 240, 380), (64, 520, 640)\n",
      "The original spacing is [[0.5938000082969666, 0.5938000082969666, 3.5]]\n",
      "[[[4, 4], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([172, 238, 380])\n",
      "The resampled shape is torch.Size([2, 172, 238, 380])\n",
      "The original shape is (160, 300, 380), (38, 320, 320)\n",
      "The original spacing is [[1.1875, 1.1875, 5.0]]\n",
      "[[[7, 7], [4, 4], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([146, 292, 380])\n",
      "The resampled shape is torch.Size([2, 146, 292, 380])\n",
      "The original shape is (180, 240, 380), (64, 520, 640)\n",
      "The original spacing is [[0.5938000082969666, 0.5938000082969666, 3.5]]\n",
      "[[[4, 4], [1, 1], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([172, 238, 380])\n",
      "The resampled shape is torch.Size([2, 172, 238, 380])\n",
      "The original shape is (160, 300, 380), (28, 320, 320)\n",
      "The original spacing is [[1.1875, 1.1875, 7.0]]\n",
      "[[[4, 5], [4, 4], [0, 0]]]\n",
      "Output shape after removing padding: torch.Size([151, 292, 380])\n",
      "The resampled shape is torch.Size([2, 151, 292, 380])\n"
     ]
    }
   ],
   "source": [
    "# from utils import Resampling_back\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "\n",
    "Test_Path = \"/data/hdc/jincan/long_seg/MICCAI25/Resampling/val\"\n",
    "dir_list = os.listdir(Test_Path)\n",
    "for idx in range(len(dir_list)):\n",
    "    image_path = os.path.join(Test_Path, dir_list[idx], \"GED4.npy\")\n",
    "    image_np = np.load(image_path)\n",
    "    mask_path = os.path.join(Test_Path, dir_list[idx], \"mask_GED4.npy\")\n",
    "    mask_np = np.load(mask_path)\n",
    "    print(f\"The original shape is {image_np.shape}, {mask_np.shape}\")\n",
    "    metadata_path = os.path.join(Test_Path, dir_list[idx], \"metadata.json\")\n",
    "    metadata = json.load(open(metadata_path, \"r\"))\n",
    "    image_np = np.expand_dims(image_np, axis=0)  # Add batch dimension\n",
    "    original_spacing = [metadata[\"original_spacing\"]]\n",
    "    print(f\"The original spacing is {original_spacing}\")\n",
    "    original_origin = [metadata[\"original_origin\"]]\n",
    "    original_direction = [metadata[\"original_direction\"]]\n",
    "    padding_info = [metadata[\"padding_info\"]]\n",
    "\n",
    "    # onehot = np.eye(2)[image_np]       # shape: [D, H, W, C]\n",
    "    # onehot = onehot.transpose(3, 0, 1, 2)\n",
    "    image_np = tensor(image_np)  # Convert to tensor if using PyTorch, otherwise keep as numpy array\n",
    "    image_np = Resampling_back(image_np, original_spacing, original_origin, original_direction, padding_info)\n",
    "    print(f\"The resampled shape is {image_np.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9f3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import torch\n",
    "\n",
    "def Prediction_to_nii(output_dict, target_spacing, original_origin, original_direction):\n",
    "    np_array = output_dict.cpu().numpy()  # Convert to numpy array\n",
    "\n",
    "    if (np_array.ndim == 4):\n",
    "        np_array = np.argmax(np_array, axis=0)  # Convert to class labels if needed\n",
    "    elif (np_array.ndim == 3):\n",
    "        np_array = np_array\n",
    "\n",
    "    image = sitk.GetImageFromArray(np_array.astype(np.uint8))  # Convert to SimpleITK image\n",
    "    image.SetSpacing(target_spacing)  # Set target spacing\n",
    "    image.SetOrigin(original_origin)  # Set original origin\n",
    "    image.SetDirection(original_direction)  # Set original direction\n",
    "    return image  # Return the SimpleITK image\n",
    "\n",
    "def resample_image(itk_image, out_spacing, is_label=False):\n",
    "    original_spacing = itk_image.GetSpacing()\n",
    "    original_size = itk_image.GetSize()\n",
    "    original_direction = itk_image.GetDirection()\n",
    "    original_origin = itk_image.GetOrigin()\n",
    "\n",
    "    out_size = [\n",
    "        int(round(osz * ospc / nspc))\n",
    "        for osz, ospc, nspc in zip(itk_image.GetSize(), original_spacing, out_spacing)\n",
    "    ]\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetOutputSpacing(out_spacing)\n",
    "    resampler.SetSize(out_size)\n",
    "    resampler.SetOutputDirection(original_direction)\n",
    "    resampler.SetOutputOrigin(original_origin)\n",
    "    resampler.SetTransform(sitk.Transform())\n",
    "    resampler.SetDefaultPixelValue(0)\n",
    "\n",
    "    if is_label:\n",
    "        resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "        # resampler.SetInterpolator(sitk.sitkLabelGaussian)\n",
    "        # resampler.SetSigma(3.0)   # 控制边界模糊的程度，数值越大越模糊（默认1.0）\n",
    "    else:\n",
    "        resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "\n",
    "    return resampler.Execute(itk_image)\n",
    "\n",
    "def Resampling_back(output_dict, original_spacing, original_origin, original_direction, padding_info):\n",
    "\n",
    "    output_dict = output_dict.squeeze(0)  # Remove batch dimension if present\n",
    "    \n",
    "    original_origin = original_origin[0]  # Assuming original_origin is a list of lists\n",
    "    original_direction = original_direction[0]  # Assuming original_direction is a list of lists\n",
    "    original_spacing = original_spacing[0]  # Assuming original_spacing is a list of lists\n",
    "\n",
    "    # Remove padding\n",
    "    print(padding_info)\n",
    "    [z0, z1]= padding_info[0][0]\n",
    "    [y0, y1] = padding_info[0][1]\n",
    "    [x0, x1] = padding_info[0][2]\n",
    "    if len(output_dict.shape) == 4:\n",
    "        output_dict = output_dict[:, z0:len(output_dict) - z1, y0:len(output_dict[0]) - y1, x0:len(output_dict[0][0]) - x1]\n",
    "    else:\n",
    "        output_dict = output_dict[z0:len(output_dict) - z1, y0:len(output_dict[0]) - y1, x0:len(output_dict[0][0]) - x1]\n",
    "\n",
    "    # print(f\"Output shape after removing padding: {output_dict.shape}\")\n",
    "    original_origin = list(map(float, original_origin))  # Convert to float\n",
    "    original_direction = list(map(float, original_direction))  # Convert to float\n",
    "    original_spacing = list(map(float, original_spacing))  # Convert to float\n",
    "    # Prediction to nii\n",
    "    pred_nii = Prediction_to_nii(output_dict, (1.0, 1.3, 1.3), original_origin, original_direction)\n",
    "\n",
    "    resampled_pred = resample_image(pred_nii, original_spacing, is_label=True)  # Resample to target spacing\n",
    "    resampled_pred = sitk.GetArrayFromImage(resampled_pred)  # Convert back to numpy array\n",
    "    # Convert to One-Hot\n",
    "    mask_tensor = torch.from_numpy(resampled_pred).long()  # Convert to tensor\n",
    "    one_hot_mask = torch.nn.functional.one_hot(mask_tensor, num_classes=2).permute(3, 0, 1, 2)  # Convert to one-hot encoding and permute to [C, D, H, W]\n",
    "    \n",
    "    return one_hot_mask  # Return the one-hot encoded mask tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4388877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original shape is (180, 240, 380), (64, 520, 640)\n",
      "[[[4, 4], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 64, 521, 640])\n",
      "The original shape is (180, 240, 380), (72, 260, 320)\n",
      "[[[7, 7], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 72, 261, 320])\n",
      "The original shape is (160, 240, 380), (64, 260, 320)\n",
      "[[[6, 6], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 64, 261, 320])\n",
      "The original shape is (200, 240, 380), (80, 260, 320)\n",
      "[[[7, 8], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 80, 261, 320])\n",
      "The original shape is (180, 240, 380), (72, 260, 320)\n",
      "[[[7, 7], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 72, 261, 320])\n",
      "The original shape is (140, 160, 300), (59, 169, 250)\n",
      "[[[2, 2], [3, 3], [1, 2]]]\n",
      "The resampled shape is torch.Size([2, 59, 169, 250])\n",
      "The original shape is (180, 240, 380), (64, 520, 640)\n",
      "[[[4, 4], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 64, 521, 640])\n",
      "The original shape is (160, 300, 380), (38, 320, 320)\n",
      "[[[7, 7], [4, 4], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 38, 320, 320])\n",
      "The original shape is (180, 240, 380), (64, 520, 640)\n",
      "[[[4, 4], [1, 1], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 64, 521, 640])\n",
      "The original shape is (160, 300, 380), (28, 320, 320)\n",
      "[[[4, 5], [4, 4], [0, 0]]]\n",
      "The resampled shape is torch.Size([2, 28, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "# from utils import Resampling_back\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "\n",
    "Test_Path = \"/data/hdc/jincan/long_seg/MICCAI25/Resampling/val\"\n",
    "dir_list = os.listdir(Test_Path)\n",
    "for idx in range(len(dir_list)):\n",
    "    image_path = os.path.join(Test_Path, dir_list[idx], \"GED4.npy\")\n",
    "    image_np = np.load(image_path)\n",
    "    mask_path = os.path.join(Test_Path, dir_list[idx], \"mask_GED4.npy\")\n",
    "    mask_np = np.load(mask_path)\n",
    "    print(f\"The original shape is {image_np.shape}, {mask_np.shape}\")\n",
    "    metadata_path = os.path.join(Test_Path, dir_list[idx], \"metadata.json\")\n",
    "    metadata = json.load(open(metadata_path, \"r\"))\n",
    "    image_np = np.expand_dims(image_np, axis=0)  # Add batch dimension\n",
    "    original_spacing = [metadata[\"original_spacing\"]]\n",
    "    # print(f\"The original spacing is {original_spacing}\")\n",
    "    original_origin = [metadata[\"original_origin\"]]\n",
    "    original_direction = [metadata[\"original_direction\"]]\n",
    "    padding_info = [metadata[\"padding_info\"]]\n",
    "\n",
    "    # onehot = np.eye(2)[image_np]       # shape: [D, H, W, C]\n",
    "    # onehot = onehot.transpose(3, 0, 1, 2)\n",
    "    image_np = tensor(image_np)  # Convert to tensor if using PyTorch, otherwise keep as numpy array\n",
    "    image_np = Resampling_back(image_np, original_spacing, original_origin, original_direction, padding_info)\n",
    "    print(f\"The resampled shape is {image_np.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
