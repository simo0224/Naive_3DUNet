{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0334c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = \"Resampling_Data\"\n",
    "OUTPUT_PATH = \"Padding_Data\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, \"val\"), exist_ok=True)\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"train\")\n",
    "VAL_DATA_PATH = os.path.join(DATA_PATH, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7964e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import json\n",
    "\n",
    "def pad_to_multiple(array, multiple=32, mode='constant', value=0):\n",
    "    \"\"\"\n",
    "    Pad array so that each spatial dimension is a multiple of `multiple`.\n",
    "    Returns padded array and padding info: [(pad_before, pad_after), ...]\n",
    "    \"\"\"\n",
    "    shape = array.shape\n",
    "    pad_width = []\n",
    "    \n",
    "    for dim in shape:\n",
    "        total_pad = (multiple - dim % multiple) % multiple\n",
    "        pad_before = total_pad // 2\n",
    "        pad_after = total_pad - pad_before\n",
    "        pad_width.append((pad_before, pad_after))\n",
    "\n",
    "    padded = np.pad(array, pad_width, mode=mode, constant_values=value)\n",
    "    return padded, pad_width\n",
    "\n",
    "def update_metadata_with_padding(metadata, pad_width):\n",
    "    metadata['padding'] = pad_width\n",
    "    return metadata\n",
    "\n",
    "def process_and_pad(dir_name, image_path, mask_path, metadata_path, out_path, padding_multiple=32):\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    # Load data\n",
    "    image = np.load(image_path)\n",
    "    mask = np.load(mask_path)\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Padding\n",
    "    padded_image, pad_width_img = pad_to_multiple(image, multiple=padding_multiple, mode='constant', value=0)\n",
    "    padded_mask, pad_width_mask = pad_to_multiple(mask, multiple=padding_multiple, mode='constant', value=0)\n",
    "\n",
    "    assert pad_width_img == pad_width_mask, \"Image and mask padding must match\"\n",
    "\n",
    "    # Update metadata\n",
    "    updated_metadata = update_metadata_with_padding(metadata, pad_width_img)\n",
    "\n",
    "    # Save\n",
    "    # print(padded_image.shape)\n",
    "    # print(padded_image.shape)\n",
    "    # print(padded_image.nbytes / 1024**3, \"GB\")  # 打印大小（单位：GB）\n",
    "    # basename = os.path.splitext(os.path.basename(image_path))[0].replace(\"_resampled\", \"\")\n",
    "    # test_array = np.zeros((100, 100, 100), dtype=np.float32)\n",
    "    # np.save(os.path.join(out_path, \"test.npy\"), test_array)\n",
    "\n",
    "    np.save(os.path.join(out_path, \"GED4.npy\"), padded_image)\n",
    "    np.save(os.path.join(out_path, \"mask_GED4.npy\"), padded_mask)\n",
    "\n",
    "    with open(os.path.join(out_path, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(updated_metadata, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Padded data saved to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f371c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded data saved to Padding_Data/train/0487-B1-S2\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Not enough free space to write 51118080 bytes after offset 128",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     tmp_metadata = os.path.join(TRAIN_DATA_PATH, dir_name, \u001b[33m\"\u001b[39m\u001b[33mmetadata.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m     output_dir = os.path.join(OUTPUT_PATH, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, dir_name)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     padded_GED4 = \u001b[43mprocess_and_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_GED4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_multiple\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m dir_list = os.listdir(VAL_DATA_PATH)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, dir_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dir_list):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mprocess_and_pad\u001b[39m\u001b[34m(dir_name, image_path, mask_path, metadata_path, out_path, padding_multiple)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# print(padded_image.shape)\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# print(padded_image.shape)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# test_array = np.zeros((100, 100, 100), dtype=np.float32)\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# np.save(os.path.join(out_path, \"test.npy\"), test_array)\u001b[39;00m\n\u001b[32m     51\u001b[39m np.save(os.path.join(out_path, \u001b[33m\"\u001b[39m\u001b[33mGED4.npy\u001b[39m\u001b[33m\"\u001b[39m), padded_image)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmask_GED4.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(out_path, \u001b[33m\"\u001b[39m\u001b[33mmetadata.json\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     55\u001b[39m     json.dump(updated_metadata, f, indent=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:584\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(file, arr, allow_pickle, fix_imports)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[32m    583\u001b[39m     arr = np.asanyarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfix_imports\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/numpy/lib/_format_impl.py:772\u001b[39m, in \u001b[36mwrite_array\u001b[39m\u001b[34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m             fp.write(chunk.tobytes(\u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m isfileobj(fp):\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m     \u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy.nditer(\n\u001b[32m    775\u001b[39m             array, flags=[\u001b[33m'\u001b[39m\u001b[33mexternal_loop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbuffered\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzerosize_ok\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    776\u001b[39m             buffersize=buffersize, order=\u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[31mOSError\u001b[39m: Not enough free space to write 51118080 bytes after offset 128"
     ]
    }
   ],
   "source": [
    "dir_list = os.listdir(TRAIN_DATA_PATH)\n",
    "for idx, dir_name in enumerate(dir_list):\n",
    "    if not os.path.isdir(os.path.join(TRAIN_DATA_PATH, dir_name)):\n",
    "        continue\n",
    "    tmp_GED4 = os.path.join(TRAIN_DATA_PATH, dir_name, \"GED4.npy\")\n",
    "    tmp_mask = os.path.join(TRAIN_DATA_PATH, dir_name, \"mask_GED4.npy\")\n",
    "    tmp_metadata = os.path.join(TRAIN_DATA_PATH, dir_name, \"metadata.json\")\n",
    "    \n",
    "    output_dir = os.path.join(OUTPUT_PATH, \"train\", dir_name)\n",
    "    padded_GED4 = process_and_pad(dir_name, tmp_GED4, tmp_mask, tmp_metadata, output_dir, padding_multiple=32)\n",
    "\n",
    "dir_list = os.listdir(VAL_DATA_PATH)\n",
    "for idx, dir_name in enumerate(dir_list):\n",
    "    if not os.path.isdir(os.path.join(VAL_DATA_PATH, dir_name)):\n",
    "        continue\n",
    "    tmp_GED4 = os.path.join(VAL_DATA_PATH, dir_name, \"GED4.npy\")\n",
    "    tmp_mask = os.path.join(VAL_DATA_PATH, dir_name, \"mask_GED4.npy\")\n",
    "    tmp_metadata = os.path.join(VAL_DATA_PATH, dir_name, \"metadata.json\")\n",
    "    \n",
    "    output_dir = os.path.join(OUTPUT_PATH, \"val\", dir_name)\n",
    "    padded_GED4 = process_and_pad(dir_name, tmp_GED4, tmp_mask, tmp_metadata, output_dir, padding_multiple=32)\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
